# Ninai Backend Environment Configuration
# Copy this file to .env and edit values as needed

# Application
APP_NAME=Ninai
APP_ENV=development
DEBUG=True
LOG_LEVEL=INFO

# API
API_HOST=0.0.0.0
API_PORT=8000
API_PREFIX=/api/v1
CORS_ORIGINS=["http://localhost:3000"]

# Security
SECRET_KEY=your-super-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# Database
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=ninai
POSTGRES_PASSWORD=ninai_dev_password
POSTGRES_DB=ninai

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
PERMISSION_CACHE_TTL=300
SHORT_TERM_TTL=604800

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=memories

# Elasticsearch
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_USER=elastic
ELASTICSEARCH_PASSWORD=

# Celery
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# LLM (Optional)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# Ollama LLM Service Configuration
# NOTE: OLLAMA_BASE_URL is preferred; OLLAMA_URL is supported for backward compatibility.
# Local runs: http://localhost:11434
# docker-compose runs: http://ollama:11434
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b
OLLAMA_TIMEOUT_SECONDS=5

# Advanced override: force heuristic mode for all agents (disables LLM calls)
# AGENT_STRATEGY=heuristic

# Optional per-agent override (metadata only)
# METADATA_EXTRACTION_STRATEGY=heuristic

# Default LLM prompt for summarizing short-term to long-term memory
SUMMARY_PROMPT="Summarize the following short-term memories into a concise, factual long-term memory entry. Focus on key actions, decisions, and important context."
